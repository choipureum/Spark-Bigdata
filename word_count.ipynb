{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local\",\"my first spark app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_in = sc.textFile(\"sample.in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = file_in.flatMap(lambda line: line.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyvalue = lines.map(lambda word:(word,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = keyvalue.reduceByKey(lambda a,b:a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Apache', 7), ('Spark', 14), ('is', 7), ('an', 3), ('open-source', 1), ('distributed', 8), ('general-purpose', 1), ('cluster-computing', 1), ('framework.', 1), ('provides', 1), ('interface', 3), ('for', 6), ('programming', 2), ('entire', 1), ('clusters', 1), ('with', 3), ('implicit', 1), ('data', 5), ('parallelism', 1), ('and', 6), ('fault', 1), ('tolerance.', 1), ('Originally', 1), ('developed', 2), ('at', 1), ('the', 23), ('University', 1), ('of', 13), ('California,', 1), (\"Berkeley's\", 1), ('AMPLab,', 1), ('codebase', 1), ('was', 3), ('later', 1), ('donated', 1), ('to', 4), ('Software', 1), ('Foundation,', 1), ('which', 4), ('has', 2), ('maintained', 2), ('it', 1), ('since.', 1), ('as', 4), ('its', 2), ('architectural', 1), ('foundation', 1), ('Resilient', 1), ('Distributed', 2), ('Dataset', 4), ('(RDD),', 1), ('a', 17), ('read-only', 1), ('multiset', 1), ('items', 1), ('over', 1), ('cluster', 5), ('machines,', 1), ('that', 2), ('in', 6), ('fault-tolerant', 1), ('way.[2]', 1), ('The', 3), ('Dataframe', 1), ('API', 3), ('released', 1), ('abstraction', 1), ('on', 5), ('top', 1), ('RDD,', 1), ('followed', 1), ('by', 3), ('API.', 1), ('In', 1), ('1.x,', 1), ('RDD', 3), ('primary', 1), ('application', 1), ('(API),', 1), ('but', 1), ('2.x', 1), ('use', 2), ('encouraged[3]', 1), ('even', 1), ('though', 1), ('not', 2), ('deprecated.[4][5]', 1), ('technology', 1), ('still', 1), ('underlies', 1), ('API.[6][7]', 1), ('RDDs', 2), ('were', 1), ('2012', 1), ('response', 1), ('limitations', 1), ('MapReduce', 3), ('computing', 1), ('paradigm,', 1), ('forces', 1), ('particular', 1), ('linear', 1), ('dataflow', 1), ('structure', 1), ('programs:', 1), ('programs', 2), ('read', 1), ('input', 1), ('from', 1), ('disk,', 1), ('map', 1), ('function', 2), ('across', 1), ('data,', 1), ('reduce', 1), ('results', 2), ('map,', 1), ('store', 1), ('reduction', 1), ('disk.', 1), (\"Spark's\", 1), ('working', 1), ('set', 2), ('offers', 1), ('(deliberately)', 1), ('restricted', 1), ('form', 1), ('shared', 1), ('memory.[8]', 1), ('facilitates', 1), ('implementation', 1), ('both', 1), ('iterative', 2), ('algorithms,', 1), ('visit', 1), ('their', 1), ('multiple', 1), ('times', 1), ('loop,', 1), ('interactive/exploratory', 1), ('analysis,', 1), ('i.e.,', 1), ('repeated', 1), ('database-style', 1), ('querying', 1), ('data.', 1), ('latency', 1), ('such', 2), ('applications', 1), ('may', 1), ('be', 3), ('reduced', 1), ('several', 1), ('orders', 1), ('magnitude', 1), ('compared', 1), ('Hadoop', 3), ('implementation.[2][9]', 1), ('Among', 1), ('class', 1), ('algorithms', 2), ('are', 1), ('training', 1), ('machine', 3), ('learning', 1), ('systems,', 1), ('formed', 1), ('initial', 1), ('impetus', 1), ('developing', 1), ('Spark.[10]', 1), ('requires', 1), ('manager', 1), ('storage', 2), ('system.', 1), ('For', 2), ('management,', 1), ('supports', 2), ('standalone', 1), ('(native', 1), ('cluster,', 1), ('where', 2), ('you', 1), ('can', 4), ('launch', 2), ('either', 1), ('manually', 1), ('or', 4), ('scripts', 1), ('provided', 1), ('install', 1), ('package.', 1), ('It', 1), ('also', 2), ('possible', 1), ('run', 2), ('these', 1), ('daemons', 1), ('single', 2), ('testing),', 1), ('YARN,', 1), ('Mesos', 1), ('Kubernetes.', 1), ('[11]', 1), ('storage,', 1), ('wide', 1), ('variety,', 1), ('including', 1), ('Alluxio,', 1), ('File', 2), ('System', 2), ('(HDFS),[12]', 1), ('MapR', 1), ('(MapR-FS),[13]', 1), ('Cassandra,[14]', 1), ('OpenStack', 1), ('Swift,', 1), ('Amazon', 1), ('S3,', 1), ('Kudu,', 1), ('Lustre', 1), ('file', 2), ('system,[15]', 1), ('custom', 1), ('solution', 1), ('implemented.', 1), ('pseudo-distributed', 1), ('local', 2), ('mode,', 1), ('usually', 1), ('used', 2), ('only', 1), ('development', 1), ('testing', 1), ('purposes,', 1), ('required', 1), ('system', 1), ('instead;', 1), ('scenario,', 1), ('one', 1), ('executor', 1), ('per', 1), ('CPU', 1), ('core.', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(word_counts.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425\n"
     ]
    }
   ],
   "source": [
    "sum=0\n",
    "for(_,n)in word_counts.collect():\n",
    "    sum+=n\n",
    "\n",
    "print(sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
